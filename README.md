# Proyecto cierre m贸dulo 3: An谩lisis de E-commerce
Repositorio dedicado al an谩lisis exploratorio, limpieza y transformaci贸n de datos de un entorno e-commerce utilizando Python.

## Descripci贸n del Proyecto
Este proyecto consiste en el desarrollo de un flujo de trabajo automatizado para la obtenci贸n, limpieza y estructuraci贸n de datos de una empresa de e-commerce. El objetivo es transformar datos crudos provenientes de m煤ltiples fuentes (CSV, Excel, Web) en un dataset confiable listo para modelos de Machine Learning y reportes estrat茅gicos.

##  Estructura del Proyecto
- `clase1_numpy.py`: Generaci贸n y fundamentos de arrays.
- `clase2_panda.py`: Estructuras de datos (Series y DataFrames).
- `clase3_extraccion.py`: Lectura de fuentes externas (CSV, Excel, Web).
- `clase4_limpieza.py`: Tratamiento de nulos y Outliers (IQR).
- `clase5_wrangling.py`: Transformaci贸n avanzada y enriquecimiento.
- `clase6_reportes.py`: Agrupamiento y tablas din谩micas finales.

## Datos
Los datasets procesados se encuentran en la carpeta `/data`.

## Tecnolog铆as
- Python 3.13+
- Pandas / NumPy
- Openpyxl / Lxml

## Avance por Clases
### Clase 1: Cimentaci贸n con NumPy
- Generaci贸n de un conjunto de datos ficticio de clientes y transacciones.
- Implementaci贸n de operaciones estad铆sticas b谩sicas para an谩lisis preliminar.
- Exportaci贸n de datos en formato binario (`.npy`) para asegurar la integridad de los tipos de datos.

### Clase 2: Estructuraci贸n con Pandas
- Transformaci贸n de arreglos NumPy a **DataFrames**.
- Exploraci贸n de datos usando `.describe()`, `.info()` y `.value_counts()`.
- Aplicaci贸n de **filtros condicionales** para segmentar transacciones de alto valor.
- Exportaci贸n a formato **CSV** para estandarizaci贸n de procesos.

### Clase 3: Extracci贸n Multi-fuente
- Implementaci贸n de `read_csv` con optimizaci贸n de tipos de datos (`dtype`).
- Manejo de archivos Excel mediante `read_excel` y la librer铆a `openpyxl`.
- **Web Scraping** b谩sico: Uso de `read_html` para capturar datos financieros en tiempo real.
- Aplicaci贸n de t茅cnicas de ahorro de memoria (`usecols`) y manejo de codificaciones (`encoding`).

### Clase 4: Manejo de Valores Perdidos y Outliers
- Uso de `isnull().sum()` para dimensionar la falta de datos.
- Aplicaci贸n de la **Mediana** para valores num茅ricos (Monto) para mitigar el sesgo de valores extremos.
- Aplicaci贸n de la **Moda** para variables discretas (Cantidad).
- **Tratamiento de Outliers:** Implementaci贸n del m茅todo del **Rango Intercuart铆lico (IQR)** para filtrar registros que distorsionan el an谩lisis estad铆stico.
- Reducci贸n de ruido en el dataset y creaci贸n de `dataset_limpio.csv`.

### Clase 5: Data Wrangling y Enriquecimiento
- Segmentaci贸n de transacciones en categor铆as ('Econ贸mica', 'Est谩ndar', 'Premium') para facilitar el an谩lisis de marketing.
- Uso de funciones **Lambda** y `.apply()` para c谩lculos din谩micos de impuestos y totales.
- Renombramiento de columnas y reordenamiento estrat茅gico de filas para mejorar la legibilidad del reporte final.
- Conversi贸n de tipos de datos (`astype`) para asegurar la eficiencia en el procesamiento de grandes vol煤menes.

### Clase 6: Agrupamiento, Pivoteo e Integraci贸n Final
- Uso de `pd.merge()` para consolidar datos de ventas con el cat谩logo de productos (similares a JOINs en SQL).
- Implementaci贸n de `groupby()` con m煤ltiples funciones estad铆sticas (`agg`) para extraer m茅tricas de negocio.
- Creaci贸n de **Tablas Pivot** para cruzar categor铆as de productos con segmentos de precio.
- Generaci贸n de reportes finales en formatos CSV y Excel para la toma de decisiones gerenciales.

---

## Conclusi贸n del Proyecto
Se ha implementado un flujo de datos (Pipeline) completo que:
1. **Obtiene** datos de fuentes heterog茅neas (NumPy, CSV, Excel, Web).
2. **Limpia** errores, nulos y outliers (IQR).
3. **Transforma** y enriquece la informaci贸n (Lambda, Binning).
4. **Analiza** y reporta resultados mediante agrupaciones complejas.

**El dataset final es confiable, estructurado y est谩 listo para ser consumido por modelos de Machine Learning o herramientas de visualizaci贸n como Power BI.**
