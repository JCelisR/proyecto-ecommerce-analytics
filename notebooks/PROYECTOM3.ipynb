{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 1 - GENERACI√ìN DE DATOS SIMULADOS PARA E-COMMERCE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Configuraci√≥n del generador de n√∫meros aleatorios\n",
        "rng = np.random.default_rng(seed=42)\n",
        "n_clientes = 500\n",
        "\n",
        "# 1. GENERACI√ìN DE DATOS BASE CON ARRAYS\n",
        "ids = np.arange(1, n_clientes + 1)\n",
        "\n",
        "nombres_base = np.array([\n",
        "    \"Ana\", \"Sof√≠a\", \"Camila\", \"Valentina\", \"Isidora\", \"Martina\",\n",
        "    \"Mateo\", \"Benjam√≠n\", \"Tom√°s\", \"Vicente\", \"Lucas\", \"Joaqu√≠n\",\n",
        "    \"Daniela\", \"Fernanda\", \"Ignacio\", \"Gabriel\", \"Antonia\", \"Catalina\"\n",
        "])\n",
        "\n",
        "apellidos_base = np.array([\n",
        "    \"Gonz√°lez\", \"Mu√±oz\", \"Rojas\", \"D√≠az\", \"P√©rez\", \"Soto\",\n",
        "    \"Contreras\", \"Silva\", \"Mart√≠nez\", \"Sep√∫lveda\", \"Torres\", \"Flores\"\n",
        "])\n",
        "\n",
        "# Creamos los nombres completos combinando aleatoriamente\n",
        "nombres = rng.choice(nombres_base, size=n_clientes) + \" \" + rng.choice(apellidos_base, size=n_clientes)\n",
        "\n",
        "# Ciudades con probabilidades espec√≠ficas (Chile)\n",
        "ciudades = np.array([\"Santiago\", \"Valpara√≠so\", \"Concepci√≥n\", \"La Serena\", \"Antofagasta\", \"Temuco\", \"Rancagua\"])\n",
        "ciudad = rng.choice(ciudades, size=n_clientes, p=[0.45, 0.12, 0.14, 0.08, 0.08, 0.08, 0.05])\n",
        "\n",
        "# 2. C√ÅLCULOS ESTAD√çSTICOS VECTORIZADOS\n",
        "# Edad: Distribuci√≥n normal (promedio 35 a√±os)\n",
        "edad = np.clip(rng.normal(loc=35, scale=12, size=n_clientes), 18, 70).round(0).astype(int)\n",
        "\n",
        "# Total_Compras: Distribuci√≥n de Poisson (promedio 4.5 compras)\n",
        "total_compras = rng.poisson(lam=4.5, size=n_clientes)\n",
        "total_compras = np.clip(total_compras, 0, 35)\n",
        "\n",
        "# Ticket promedio y Monto Total con ruido aleatorio\n",
        "ticket_promedio = rng.lognormal(mean=np.log(25000), sigma=0.55, size=n_clientes)\n",
        "monto_total = (total_compras * ticket_promedio) + rng.normal(0, 5000, size=n_clientes)\n",
        "monto_total = np.clip(monto_total, 0, None).round(0).astype(int)\n",
        "\n",
        "# 3. OPERACIONES MATEM√ÅTICAS B√ÅSICAS (NumPy)\n",
        "print(f\"--- Estad√≠sticas Iniciales (NumPy) ---\")\n",
        "print(f\"Monto Total de Ventas: ${np.sum(monto_total)}\")\n",
        "print(f\"Promedio de Edad de Clientes: {np.mean(edad):.1f} a√±os\")\n",
        "print(f\"M√°ximo de compras por un cliente: {np.max(total_compras)}\")\n",
        "\n",
        "# 4. ESTRUCTURACI√ìN Y GUARDADO\n",
        "# Creamos la carpeta 'data' si no existe\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Creamos un DataFrame para visualizaci√≥n y exportaci√≥n\n",
        "clientes = pd.DataFrame({\n",
        "    \"ID\": ids,\n",
        "    \"Nombre\": nombres,\n",
        "    \"Edad\": edad,\n",
        "    \"Ciudad\": ciudad,\n",
        "    \"Total_Compras\": total_compras,\n",
        "    \"Monto_Total\": monto_total\n",
        "})\n",
        "\n",
        "# 5. GUARDAR Y PREPARAR PARA LA SIGUIENTE CLASE\n",
        "# Guardamos en formato binario .npy para la siguiente clase\n",
        "np.save(r'C:\\Users\\jceli\\Bootcamp\\proyecto-ecommerce-analytics\\data\\transacciones_iniciales.npy', monto_total)\n",
        "\n",
        "# Tambi√©n exportamos el CSV inicial para la siguiente clase\n",
        "clientes.to_csv(r'C:\\Users\\jceli\\Bootcamp\\proyecto-ecommerce-analytics\\data\\dataset_transacciones.csv', index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Proceso completado: Archivo 'data\\transacciones_iniciales.npy' guardado.\")\n",
        "print(\"\\n--- Primeros 5 registros del DataFrame ---\")\n",
        "print(clientes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 2 - EXPLORACI√ìN INICIAL DE DATOS CON PANDAS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. CARGA DE DATOS\n",
        "# Cargamos el archivo que creamos con NumPy en clase 1\n",
        "try:\n",
        "    df = pd.read_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_transacciones.csv')\n",
        "    data_numpy = np.load('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\transacciones_iniciales.npy')\n",
        "    print(\"‚úÖ Datos cargados exitosamente desde NumPy.\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: No se encontr√≥ el archivo .npy. Aseg√∫rate de ejecutar la Clase 1 primero.\")\n",
        "\n",
        "# 2. EXPLORACI√ìN INICIAL\n",
        "print(\"\\n--- Primeras 5 filas ---\")\n",
        "print(df.head())  # Visualizar primeras filas \n",
        "\n",
        "print(\"\\n--- √öltimas 5 filas ---\")\n",
        "print(df.tail())  # Visualizar √∫ltimas filas\n",
        "\n",
        "print(\"\\n--- Informaci√≥n General ---\")\n",
        "print(df.info())  # Inspecci√≥n de tipos de datos y nulos \n",
        "\n",
        "print(\"\\n--- Estad√≠sticas Descriptivas ---\")\n",
        "print(df.describe())  # Estad√≠sticas b√°sicas \n",
        "\n",
        "# 3. FILTROS CONDICIONALES\n",
        "# Ejemplo: Transacciones con monto total mayor a 100,000\n",
        "ventas_altas = df[df['Monto_Total'] > 100000]\n",
        "print(f\"\\nüöÄ Cantidad de ventas > 100,000: {len(ventas_altas)}\")\n",
        "\n",
        "# Ejemplo: Clientes con m√°s de 4 compras\n",
        "clientes_frecuentes = df[df['Total_Compras'] > 4]\n",
        "print(f\"üõí Cantidad de clientes frecuentes (>4 compras): {len(clientes_frecuentes)}\")\n",
        "\n",
        "# 4. SUMARIZACI√ìN Y VALORES √öNICOS\n",
        "print(\"\\n--- Clientes por Ciudad ---\")\n",
        "print(df['Ciudad'].value_counts())  # Conteo por categor√≠as\n",
        "\n",
        "print(\"\\n--- Ciudades √önicas ---\")\n",
        "print(df['Ciudad'].unique())  # Identificar valores √∫nicos\n",
        "\n",
        "# 5. GUARDAR PARA LA SIGUIENTE CLASE (Limpieza)\n",
        "df.to_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_explorado.csv', index=False)\n",
        "print(\"\\n‚úÖ Dataset estructurado guardado como 'data/dataset_explorado.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 3 - INTEGRACI√ìN DE M√öLTIPLES FUENTES DE DATOS\n",
        "import pandas as pd\n",
        "import requests # Librer√≠a necesaria para consultar APIs\n",
        "\n",
        "# 1. CARGA DEL CSV (Ventas del E-commerce)\n",
        "    # Cargamos el archivo generado en la Clase 2\n",
        "try:\n",
        "    df_ventas = pd.read_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_explorado.csv')\n",
        "    print(\"‚úÖ CSV de ventas cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ el archivo. Verifique la Clase 2.\")\n",
        "\n",
        "# 2. CARGA DE EXCEL\n",
        "try:\n",
        "    # Simulamos un cat√°logo de categor√≠as\n",
        "    df_categorias = pd.DataFrame({\n",
        "        'ID_Producto': [1, 2, 3, 4, 5],\n",
        "        'Categoria': ['Electr√≥nica', 'Hogar', 'Moda', 'Deportes', 'Juguetes']\n",
        "    })\n",
        "    df_categorias.to_excel('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\categorias_productos.xlsx', index=False)\n",
        "    df_excel = pd.read_excel('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\categorias_productos.xlsx')\n",
        "    print(\"‚úÖ Archivo Excel de categor√≠as cargado.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error con Excel: {e}\")\n",
        "\n",
        "# 3. EXTRACCI√ìN WEB (API mindicador.cl)\n",
        "try:\n",
        "    url_api = \"https://mindicador.cl/api/dolar\"\n",
        "    response = requests.get(url_api)\n",
        "    data = response.json()\n",
        "    \n",
        "    # Extraemos el valor del d√≥lar m√°s reciente\n",
        "    valor_dolar = data['serie'][0]['valor']\n",
        "    print(f\"‚úÖ Valor del d√≥lar extra√≠do de la API: ${valor_dolar}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error al consultar la API: {e}\")\n",
        "    valor_dolar = 950.0         # Valor de respaldo (Plan de contingencia)\n",
        "\n",
        "# Consult√© a Gemini por errores como el 429, entre otros y me sugiri√≥ utilizar la p√°gina con API.\n",
        "# Esto lo realic√© con ayuda de Gemini, ya que no estaba en el material del curso.\n",
        "# Es muy complejo extraer datos de p√°ginas que tienen protecciones, incluso del sii.cl\n",
        "\n",
        "# 4. UNIFICACI√ìN DE FUENTES\n",
        "# En esta etapa consolidamos la informaci√≥n para la limpieza futura\n",
        "df_consolidado = df_ventas.copy()\n",
        "df_consolidado['Valor_Dolar_Referencia'] = valor_dolar\n",
        "df_consolidado['Fuente_Dolar'] = \"mindicador.cl\"\n",
        "\n",
        "# 5. GUARDAR DATOS CONSOLIDADOS\n",
        "# Consolidamos las ventas en un nuevo archivo para la Clase 4 (Limpieza)\n",
        "df_consolidado.to_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\ventas_consolidadas.csv', index=False, sep=';')\n",
        "print(\"\\n Dataset consolidado guardado en 'data/ventas_consolidadas.csv' listo para limpieza.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 4 - LIMPIEZA Y PREPARACI√ìN DE DATOS PARA AN√ÅLISIS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. CARGA DE DATOS (Conexi√≥n con Clase 3)\n",
        "try:\n",
        "    df = pd.read_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\ventas_consolidadas.csv', sep=';', encoding='latin1')\n",
        "    print(\"‚úÖ Dataset cargado para limpieza.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: Ejecuta primero la Clase 3.\")\n",
        "    exit()\n",
        "\n",
        "# Insertamos algunos nulos y duplicados aleatorios\n",
        "df.loc[df.sample(frac=0.05).index, 'Edad'] = np.nan\n",
        "df = pd.concat([df, df.iloc[:5]], ignore_index=True) \n",
        "\n",
        "# 2. GESTI√ìN DE NULOS Y DUPLICADOS\n",
        "print(f\"\\n Nulos detectados:\\n{df.isnull().sum()}\")\n",
        "print(f\" Duplicados iniciales: {df.duplicated().sum()}\")\n",
        "\n",
        "# Decisiones de limpieza:\n",
        "df.drop_duplicates(inplace=True) # Eliminamos duplicados\n",
        "df['Edad'] = df['Edad'].fillna(df['Edad'].median()) # Imputaci√≥n por mediana\n",
        "\n",
        "# 3. DETECCI√ìN DE OUTLIERS (M√©todo IQR)\n",
        "# El IQR es ideal para variables financieras\n",
        "Q1 = df['Monto_Total'].quantile(0.25)\n",
        "Q3 = df['Monto_Total'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "limite_inferior = Q1 - 1.5 * IQR\n",
        "limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['Monto_Total'] < limite_inferior) | (df['Monto_Total'] > limite_superior)]\n",
        "print(f\"\\n Outliers detectados en Monto_Total: {len(outliers)}\")\n",
        "\n",
        "# Filtramos el dataset para mantener solo datos \"normales\"\n",
        "df_limpio = df[(df['Monto_Total'] >= limite_inferior) & (df['Monto_Total'] <= limite_superior)]\n",
        "\n",
        "# 5. GUARDAR DATASET LIMPIO PARA LA SIGUIENTE CLASE\n",
        "df_limpio.to_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_limpio.csv', index=False, sep=';', encoding='latin1')\n",
        "print(\"\\n Dataset limpio guardado en 'data/dataset_limpio.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 5 - DATA WRANGLING Y TRANSFORMACI√ìN AVANZADA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. CARGA DE DATOS (Conexi√≥n con Clase 4)\n",
        "try:\n",
        "    # Cargamos el dataset que ya no tiene nulos ni outliers extremos\n",
        "    df = pd.read_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_limpio.csv', sep=';', encoding='latin1')\n",
        "    print(\"‚úÖ Dataset limpio cargado para Data Wrangling.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: Ejecuta primero la Clase 4.\")\n",
        "    exit()\n",
        "\n",
        "# 2. TRANSFORMACI√ìN DE TIPOS DE DATOS\n",
        "# Aseguramos que los tipos sean correctos para c√°lculos y ahorro de memoria\n",
        "df['ID'] = df['ID'].astype(int)\n",
        "df['Total_Compras'] = df['Total_Compras'].astype(np.int32)\n",
        "df['Monto_Total'] = df['Monto_Total'].astype(float)\n",
        "\n",
        "# 3. CREACI√ìN DE COLUMNAS CALCULADAS Y FUNCIONES LAMBDA\n",
        "# Calculamos el Ticket Promedio por cliente\n",
        "df['Ticket_Promedio'] = (df['Monto_Total'] / df['Total_Compras']).round(2)\n",
        "\n",
        "# Aplicamos una funci√≥n personalizada con lambda para categorizar por edad\n",
        "df['Segmento_Etario'] = df['Edad'].apply(lambda x: 'Joven' if x < 30 else ('Adulto' if x < 60 else 'S√©nior'))\n",
        "\n",
        "# 4. NORMALIZACI√ìN Y ESTRUCTURACI√ìN DE DATOS\n",
        "# Binning: Categorizamos el valor del cliente seg√∫n su gasto\n",
        "# Creamos 3 niveles: Bronce, Plata, Oro\n",
        "bins = [0, 50000, 150000, np.inf]\n",
        "labels = ['Bronce', 'Plata', 'Oro']\n",
        "df['Rango_Valor_Cliente'] = pd.cut(df['Monto_Total'], bins=bins, labels=labels)\n",
        "\n",
        "# Normalizaci√≥n simple: Score de compras (0 a 1) para identificar clientes activos\n",
        "df['Score_Actividad'] = (df['Total_Compras'] - df['Total_Compras'].min()) / (df['Total_Compras'].max() - df['Total_Compras'].min())\n",
        "\n",
        "# 5. ELIMINACI√ìN DE DUPLICADOS RESIDUALES\n",
        "# Por si la integraci√≥n de fuentes gener√≥ duplicados nuevos\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 6. EXPORTACI√ìN FINAL PARA AN√ÅLISIS DE CLASE FINAL\n",
        "df.to_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_final_wrangled.csv', index=False, sep=';', encoding='latin1')\n",
        "print(\"\\n Data Wrangling completado. Columnas nuevas: Ticket_Promedio, Segmento_Etario, Rango_Valor_Cliente.\")\n",
        "print(df[['Nombre', 'Segmento_Etario', 'Rango_Valor_Cliente', 'Score_Actividad']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLASE 6 - GENERACI√ìN DE REPORTES Y TABLAS PIVOT\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. CARGA DE DATOS \n",
        "# Conexi√≥n con Clases anteriores (1 a 5)\n",
        "try:\n",
        "    df = pd.read_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\dataset_final_wrangled.csv', sep=';', encoding='latin1')\n",
        "    # Cargamos tambi√©n el cat√°logo de Excel creado en la Clase 3\n",
        "    df_cat = pd.read_excel('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\categorias_productos.xlsx')\n",
        "    print(\"‚úÖ Datasets cargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al cargar archivos. Vuelve a ejecutar clase 5 y 3: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 2. COMBINACI√ìN DE DATOS (Merge)\n",
        "# Generamos IDs de productos aleatorios para cruzar con el cat√°logo\n",
        "df['ID_Producto'] = np.random.randint(1, 6, size=len(df))\n",
        "\n",
        "# Unimos las tablas (Data Wrangling avanzado)\n",
        "df_final = pd.merge(df, df_cat, on='ID_Producto', how='left')\n",
        "\n",
        "# 3. AGRUPAMIENTO\n",
        "# Obtenemos m√©tricas resumidas por Ciudad y Categor√≠a\n",
        "resumen_ventas = df_final.groupby(['Ciudad', 'Categoria'])['Monto_Total'].agg(['sum', 'mean', 'count']).reset_index()\n",
        "resumen_ventas.columns = ['Ciudad', 'Categoria', 'Venta_Total', 'Promedio_Venta', 'Num_Transacciones']\n",
        "\n",
        "# 4. REESTRUCTURACI√ìN (pivot_table)\n",
        "# Creamos una tabla din√°mica para ver el Total de Ventas por Categor√≠a y Segmento (Binning)\n",
        "# Creamos una matriz para comparar ventas de categor√≠as entre ciudades\n",
        "matriz_ventas = df_final.pivot_table(\n",
        "    index='Ciudad', \n",
        "    columns='Categoria', \n",
        "    values='Monto_Total', \n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(\"\\n--- TABLA PIVOT: VENTAS POR CATEGOR√çA Y SEGMENTO ---\")\n",
        "print(matriz_ventas)\n",
        "\n",
        "# 5. EXPORTACI√ìN FINAL DEL PROYECTO\n",
        "# CSV para sistemas de datos y Excel para reportes gerenciales\n",
        "df_final.to_csv('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\entrega_final_ventas.csv', index=False)\n",
        "with pd.ExcelWriter('C:\\\\Users\\\\jceli\\\\Bootcamp\\\\proyecto-ecommerce-analytics\\\\data\\\\reporte_final_analisis.xlsx') as writer:\n",
        "    df_final.to_excel(writer, sheet_name='Datos_Detallados', index=False)\n",
        "    resumen_ventas.to_excel(writer, sheet_name='Resumen_KPIs', index=False)\n",
        "    matriz_ventas.to_excel(writer, sheet_name='Matriz_Ciudades')\n",
        "\n",
        "print(\"\\nüèÜ ¬°Proyecto Finalizado! Archivos generados en la carpeta /data:\")\n",
        "print(\"- entrega_final_ventas.csv\")\n",
        "print(\"- reporte_final_analisis.xlsx (Con m√∫ltiples pesta√±as)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMguTuMAOpZbn21kDT6MJ59",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
